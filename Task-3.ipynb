{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de916c0",
   "metadata": {},
   "source": [
    "# Task-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b084851",
   "metadata": {},
   "source": [
    "# Basic web scraper using Python libraries like BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37636eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary Libraries\n",
    "\n",
    "import requests # pip install requests\n",
    "from bs4 import BeautifulSoup as bs # pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9792a",
   "metadata": {},
   "source": [
    "# Loading a web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f68b7aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!-- 2a-uber  -->\n",
      "<style>\n",
      " .uber\n",
      "    {\n",
      "        background-color:black;\n",
      "        color:white;\n",
      "        height:45px;\n",
      "        width:150px;\n",
      "        font-size:18px;\n",
      "        cursor:pointer;\n",
      "    }\n",
      "    .amazon1\n",
      "    {\n",
      "        border:none;\n",
      "        background-color: rgb(255,216,20);\n",
      "        color:black;\n",
      "        height:45px;\n",
      "        width:200px;\n",
      "        border-radius: 22px;\n",
      "        font-size: 18px;\n",
      "        cursor:pointer;\n",
      "    }\n",
      "    .amazon2\n",
      "    {\n",
      "        border:none;\n",
      "        background-color: rgb(255,164,28);\n",
      "        color:black;\n",
      "        height:45px;\n",
      "        width:200px;\n",
      "        border-radius: 22px;\n",
      "        font-size: 18px;\n",
      "        cursor:pointer;\n",
      "        margin-left:8px;\n",
      "    }\n",
      "    .GitHub\n",
      "    {\n",
      "        height:45px;\n",
      "        width:120px;\n",
      "        background-color: rgb(46,164,79);\n",
      "        border:none;\n",
      "        color:white;\n",
      "        font-weight:bold;\n",
      "        border-radius:5px;\n",
      "        font-size:18px;\n",
      "        cursor:pointer;\n",
      "    }\n",
      "    .Bootstrap1\n",
      "    {\n",
      "        border:none;\n",
      "        background-color: rgb(121,82,179);\n",
      "        color:white;\n",
      "        border-radius:4px;\n",
      "        height:45;\n",
      "        width:150px;\n",
      "        font-weight:bold;\n",
      "        font-size:18px;\n",
      "        margin-right:8px;\n",
      "        cursor:pointer;\n",
      "    }\n",
      "    .Bootstrap2\n",
      "    {\n",
      "        border-width:1px;\n",
      "        background-color:white;\n",
      "        color:rgb(108,117,125);\n",
      "        border-radius:4px;\n",
      "        height:45;\n",
      "        width:150px;\n",
      "        font-weight:bold;\n",
      "        font-size:18px;\n",
      "        cursor:pointer;\n",
      "    }\n",
      "    .LinkedIn1\n",
      "    {\n",
      "        border:none;\n",
      "        height:45px;\n",
      "        width:280px;\n",
      "        background-color: rgb(10,102,194);\n",
      "        color:white;\n",
      "        font-weight:bold;\n",
      "        font-size:18px;\n",
      "        border-radius: 22px;\n",
      "        cursor:pointer;\n",
      "    }\n",
      "    .LinkedIn2\n",
      "    {\n",
      "        border-color: rgb(10,102,194);;\n",
      "        height:45px;\n",
      "        width:100px;\n",
      "        background-color: white;\n",
      "        color:rgb(10,102,194);\n",
      "        font-weight:bold;\n",
      "        font-size:18px;\n",
      "        border-radius: 22px;\n",
      "        margin-left: 8px;\n",
      "        cursor:pointer;\n",
      "        border-style: solid;\n",
      "    }\n",
      "    .stock\n",
      "    {\n",
      "        color:rgb(0,118,0);\n",
      "    }\n",
      "    .del\n",
      "    {\n",
      "        font-weight:lighter;\n",
      "        font-size: 22px;\n",
      "    }\n",
      "</style>\n",
      "<button class=\"uber\">\n",
      " Request now\n",
      "</button>\n",
      "<hr/>\n",
      "<button class=\"amazon1\">\n",
      " Add to Cart\n",
      "</button>\n",
      "<hr/>\n",
      "<button class=\"GitHub\">\n",
      " Sign up\n",
      "</button>\n",
      "<hr/>\n",
      "<button class=\"Bootstrap1\">\n",
      " Get started\n",
      "</button>\n",
      "<button class=\"Bootstrap2\">\n",
      " Download\n",
      "</button>\n",
      "<hr/>\n",
      "<button class=\"LinkedIn1\">\n",
      " Apply on company website\n",
      "</button>\n",
      "<button class=\"LinkedIn2\">\n",
      " Save\n",
      "</button>\n",
      "<hr/>\n",
      "<a class=\"del\" href=\"https://www.amazon.in/\" target=\"_blank\">\n",
      " Back to Amazon\n",
      "</a>\n",
      "<h1>\n",
      " Nike Black Running Shoes\n",
      "</h1>\n",
      "<h2 class=\"stock\">\n",
      " $39 - in stock.\n",
      "</h2>\n",
      "<h2 class=\"del\">\n",
      " Free  delivery tomorrow.\n",
      "</h2>\n",
      "<button class=\"amazon1\">\n",
      " Add to cart\n",
      "</button>\n",
      "<button class=\"amazon2\">\n",
      " Buy now\n",
      "</button>\n"
     ]
    }
   ],
   "source": [
    "# Open and read the local HTML file\n",
    "with open(r\"C:\\Users\\JIGISHA NAYANA\\OneDrive\\Desktop\\jigi\\html css things\\baby bud\\exercise-2.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a574c28f",
   "metadata": {},
   "source": [
    "# starting to scrape - find & find_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7dbd415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1> Nike Black Running Shoes</h1>\n",
      "[<h2 class=\"stock\"> $39 - in stock.</h2>, <h2 class=\"del\">Free  delivery tomorrow.</h2>]\n"
     ]
    }
   ],
   "source": [
    "# start using beautiful soup library\n",
    "\n",
    "# find & find_all\n",
    "first_header = soup.find(\"h1\")\n",
    "print(first_header)\n",
    "first_header = soup.find_all(\"h2\")\n",
    "print(first_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff9a0bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1> Nike Black Running Shoes</h1>,\n",
       " <h2 class=\"stock\"> $39 - in stock.</h2>,\n",
       " <h2 class=\"del\">Free  delivery tomorrow.</h2>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass in a list of elements to look for\n",
    "first_header = soup.find_all([\"h1\",\"h2\"])\n",
    "first_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36ccf5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"stock\"> $39 - in stock.</h2>, <h2 class=\"del\">Free  delivery tomorrow.</h2>]\n",
      "Only Particular Attributed Element Will Be Shown\n",
      "[<h2 class=\"del\">Free  delivery tomorrow.</h2>]\n"
     ]
    }
   ],
   "source": [
    "# passing attributes to the find/find_all functions\n",
    "para = soup.find_all(\"h2\")\n",
    "print(para)\n",
    "\n",
    "print(\"Only Particular Attributed Element Will Be Shown\")\n",
    "para = soup.find_all(\"h2\",attrs={\"class\":\"del\"})\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a02b60c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2 class=\"del\">Free  delivery tomorrow.</h2>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can nest find/find_all calls\n",
    "# body = soup.find('body')\n",
    "# div = body.find('div')\n",
    "# header = div.find(\"h1\")\n",
    "\n",
    "# can search specific strings in our find/find_all\n",
    "para  = soup.find_all(\"h2\",string=\"Free  delivery tomorrow.\")\n",
    "para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f44a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"del\">Free  delivery tomorrow.</h2>]\n",
      "[<button class=\"uber\"> Request now </button>, <button class=\"amazon2\">Buy now</button>]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "para = soup.find_all(\"h2\",string=re.compile(\"Free  delivery tomorrow.\"))\n",
    "print(para)\n",
    "\n",
    "# it displays all elements with that string\n",
    "para = soup.find_all(\"button\",string=re.compile(\"now\"))\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f620f",
   "metadata": {},
   "source": [
    "# CSS path selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20422ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2 class=\"stock\"> $39 - in stock.</h2>,\n",
       " <h2 class=\"del\">Free  delivery tomorrow.</h2>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select css selector\n",
    "\n",
    "content = soup.select(\"div h1\") # h1 tag elements in div\n",
    "content\n",
    "content = soup.select(\"h1 ~  h2\") # h2 after h1\n",
    "content\n",
    "\n",
    "# bold text in paragraph element with that id\n",
    "\n",
    "    #bold_text = soup.select(\"p#id_name b\")\n",
    "    #bold_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7470883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "paragraphs = soup.select(\"body > p\") # selects all p tag elements in bosy\n",
    "print(paragraphs)\n",
    "\n",
    "for paragraph in paragraphs: # loop iteration\n",
    "    print(paragraphs.select(\"i\")) # selects all italic tag elements in p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "baa41558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>\n",
      " Nike Black Running Shoes\n",
      "</h1>\n",
      "\n",
      " Nike Black Running Shoes\n"
     ]
    }
   ],
   "source": [
    "# Grabbing string or text from html element\n",
    "header = soup.find(\"h1\")\n",
    "header\n",
    "\n",
    "print(header.prettify())\n",
    "print(header.get_text()) # useful for multiple children in that tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1dd8f1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"del\" href=\"https://www.amazon.in/\" target=\"_blank\">Back to Amazon</a>\n",
      "https://www.amazon.in/\n",
      "['del']\n"
     ]
    }
   ],
   "source": [
    "# get a specific property from an element\n",
    "link = soup.find(\"a\")\n",
    "print(link)\n",
    "print(link['href'])\n",
    "print(link['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae745804",
   "metadata": {},
   "source": [
    "# Code Navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6bc9bb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Nike Black Running Shoes'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0dffcf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   div\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <div>\n",
      "   <input class=\"searchbar\" placeholder=\"search\" type=\"textbox\"/>\n",
      "   <img class=\"thumbnail\" src=\"nandanandana img.webp\"/>\n",
      "   <p class=\"video-title\">\n",
      "    nandanandana lyrical video\n",
      "   </p>\n",
      "   <p class=\"video-channel\">\n",
      "    T-series\n",
      "   </p>\n",
      "   <p class=\"video-views\">\n",
      "    4M views 🞄 11days\n",
      "   </p>\n",
      "  </div>\n",
      "  <div id=\"link\">\n",
      "   <a href=\"https://open.spotify.com/track/1Nm6QoT9Iu5ismjmJSLpNs?si=7f387f7c0d2240b9\">\n",
      "    vurike chilaka song\n",
      "   </a>\n",
      "   <br/>\n",
      "   <a href=\"https://open.spotify.com/track/7L2D6W7e8mn0zf8cH78Ch4?si=9d7e1ec9cfdb440b\">\n",
      "    sirivennala song\n",
      "   </a>\n",
      "   <br/>\n",
      "   <a href=\"https://open.spotify.com/track/4uSdLJZ1Qoe1ckC5WGmipG?si=3d96045c15ba4656\">\n",
      "    yamuna thatilo song\n",
      "   </a>\n",
      "   <br/>\n",
      "  </div>\n",
      "  <br/>\n",
      "  <table border=\"1\">\n",
      "   <tr>\n",
      "    <th>\n",
      "     Header 1\n",
      "    </th>\n",
      "    <th>\n",
      "     Header 2\n",
      "    </th>\n",
      "    <th>\n",
      "     Header 3\n",
      "    </th>\n",
      "   </tr>\n",
      "   <tr>\n",
      "    <td>\n",
      "     11\n",
      "    </td>\n",
      "    <td>\n",
      "     12\n",
      "    </td>\n",
      "    <td>\n",
      "     13\n",
      "    </td>\n",
      "   </tr>\n",
      "   <tr>\n",
      "    <td>\n",
      "     21\n",
      "    </td>\n",
      "    <td>\n",
      "     22\n",
      "    </td>\n",
      "    <td>\n",
      "     23\n",
      "    </td>\n",
      "   </tr>\n",
      "   <tr>\n",
      "    <td>\n",
      "     31\n",
      "    </td>\n",
      "    <td>\n",
      "     32\n",
      "    </td>\n",
      "    <td>\n",
      "     33\n",
      "    </td>\n",
      "   </tr>\n",
      "  </table>\n",
      "  <ul>\n",
      "   <li>\n",
      "    This is the first sentence.\n",
      "   </li>\n",
      "   <li>\n",
      "    Here is another example sentence.\n",
      "   </li>\n",
      "   <li>\n",
      "    Is this the sentence you were looking for?\n",
      "   </li>\n",
      "   <li>\n",
      "    Learning HTML is fun and useful.\n",
      "   </li>\n",
      "   <li>\n",
      "    BeautifulSoup is a powerful library for parsing HTML.\n",
      "   </li>\n",
      "  </ul>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# loading a web page with children and parent tags\n",
    "# Open and read the local HTML file\n",
    "with open(r\"C:\\Users\\JIGISHA NAYANA\\OneDrive\\Desktop\\jigi\\html css things\\baby bud\\exercise--9.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content1 = file.read()\n",
    "\n",
    "soup1 = BeautifulSoup(content1, 'html.parser')\n",
    "\n",
    "print(soup1.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "95df1a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div id=\"link\">\n",
       " <a href=\"https://open.spotify.com/track/1Nm6QoT9Iu5ismjmJSLpNs?si=7f387f7c0d2240b9\">vurike chilaka song</a> <br/>\n",
       " <a href=\"https://open.spotify.com/track/7L2D6W7e8mn0zf8cH78Ch4?si=9d7e1ec9cfdb440b\">sirivennala song</a> <br/>\n",
       " <a href=\"https://open.spotify.com/track/4uSdLJZ1Qoe1ckC5WGmipG?si=3d96045c15ba4656\">yamuna thatilo song</a> <br/>\n",
       " </div>,\n",
       " <br/>,\n",
       " <table border=\"1\">\n",
       " <tr>\n",
       " <th>Header 1</th>\n",
       " <th>Header 2</th>\n",
       " <th>Header 3</th>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>11</td>\n",
       " <td>12</td>\n",
       " <td>13</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>21</td>\n",
       " <td>22</td>\n",
       " <td>23</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>31</td>\n",
       " <td>32</td>\n",
       " <td>33</td>\n",
       " </tr>\n",
       " </table>,\n",
       " <ul>\n",
       " <li>This is the first sentence.</li>\n",
       " <li>Here is another example sentence.</li>\n",
       " <li>Is this the sentence you were looking for?</li>\n",
       " <li>Learning HTML is fun and useful.</li>\n",
       " <li>BeautifulSoup is a powerful library for parsing HTML.</li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knowing terms - Parent, Sibling, Child\n",
    "\n",
    "soup1.body.find(\"div\").find_next_siblings() # all siblings to div tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0783cb0",
   "metadata": {},
   "source": [
    "# Grabbing all social links from web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9f58498a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://open.spotify.com/track/1Nm6QoT9Iu5ismjmJSLpNs?si=7f387f7c0d2240b9',\n",
       " 'https://open.spotify.com/track/7L2D6W7e8mn0zf8cH78Ch4?si=9d7e1ec9cfdb440b',\n",
       " 'https://open.spotify.com/track/4uSdLJZ1Qoe1ckC5WGmipG?si=3d96045c15ba4656']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = soup1.select(\"a\")\n",
    "actual_links = [link['href'] for link in links]\n",
    "actual_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "30ac385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://open.spotify.com/track/1Nm6QoT9Iu5ismjmJSLpNs?si=7f387f7c0d2240b9\">vurike chilaka song</a>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = soup1.find(\"a\")\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27939bfb",
   "metadata": {},
   "source": [
    "# Scrape a html table into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "40eac70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11', '12', '13']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header 1</th>\n",
       "      <th>Header 2</th>\n",
       "      <th>Header 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Header 1 Header 2 Header 3\n",
       "0       11       12       13\n",
       "1       21       22       23\n",
       "2       31       32       33"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table = soup1.select(\"table\")[0]\n",
    "columns = table.find_all(\"th\")\n",
    "col_names = [c.string for c in columns]\n",
    "\n",
    "table_rows = table.find_all(\"tr\")[1:]\n",
    "l=[]\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all(\"td\")\n",
    "    row = [tr.string for tr in td]\n",
    "    l.append(row)\n",
    "\n",
    "print(l[0])\n",
    "\n",
    "df = pd.DataFrame(l, columns = col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "29516377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table border=\"1\">\n",
       "<tr>\n",
       "<th>Header 1</th>\n",
       "<th>Header 2</th>\n",
       "<th>Header 3</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>11</td>\n",
       "<td>12</td>\n",
       "<td>13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>21</td>\n",
       "<td>22</td>\n",
       "<td>23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>31</td>\n",
       "<td>32</td>\n",
       "<td>33</td>\n",
       "</tr>\n",
       "</table>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf3d26fe",
   "metadata": {},
   "source": [
    "# Grab all sentenses in list with word \"is\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f8d44c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This is the first sentence.'],\n",
       " ['Here is another example sentence.'],\n",
       " ['Is this the sentence you were looking for?'],\n",
       " ['Learning HTML is fun and useful.'],\n",
       " ['BeautifulSoup is a powerful library for parsing HTML.']]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "facts = soup1.select(\"ul li\")\n",
    "facts_with_is = [fact.find_all(string = re.compile(\"is\")) for fact in facts]\n",
    "facts_with_is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10ff3e",
   "metadata": {},
   "source": [
    "# Download an image from webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8d57991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<img class=\"thumbnail\" src=\"nandanandana img.webp\"/>]\n"
     ]
    }
   ],
   "source": [
    "print(soup1.select(\"div img\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f01d3391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nandanandana img.webp\n"
     ]
    }
   ],
   "source": [
    "images = soup1.select(\"div img\")\n",
    "image_url = images[0]['src']\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ae17ca86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved successfully at: C:/Users/JIGISHA NAYANA/OneDrive/Desktop\\nandanandana img.webp\n"
     ]
    }
   ],
   "source": [
    "# downloading image\n",
    "import shutil\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "\n",
    "# Find the first <img> tag\n",
    "img_tag = soup1.find('img')\n",
    "\n",
    "if img_tag:\n",
    "    # Extract the filename from the src attribute\n",
    "    image_filename = img_tag.get('src')\n",
    "\n",
    "    # Specify the full path to the image\n",
    "    image_path = r\"C:\\Users\\JIGISHA NAYANA\\OneDrive\\Desktop\\jigi\\html css things\\baby bud\\nandanandana img.webp\"\n",
    "\n",
    "    # Specify the directory where you want to save the image\n",
    "    save_dir = 'C:/Users/JIGISHA NAYANA/OneDrive/Desktop'  # Update with your desired directory\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Specify the path to save the image\n",
    "    save_path = os.path.join(save_dir, image_filename)\n",
    "\n",
    "    # Copy the image file to the specified path\n",
    "    shutil.copyfile(image_path, save_path)\n",
    "\n",
    "    print(f'Image saved successfully at: {save_path}')\n",
    "else:\n",
    "    print('No <img> tag found on the webpage.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967e581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
